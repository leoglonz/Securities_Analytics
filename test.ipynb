{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/5l/9brv6cdn1b97f82knqyjcb4m0000gn/T/ipykernel_46365/179757321.py:84: UserWarning: Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF:https://github.com/keras-team/keras/releases/tag/2.4.0\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-03-16 11:42:37,215]\u001b[0m A new study created in memory with name: no-name-0dc7f9f3-6a5e-4b60-8faa-5bd6dc9e72ac\u001b[0m\n",
      "2023-03-16 11:42:37.360456: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-16 11:42:37.360566: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 11:42:37.555958: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-03-16 11:42:37.694984: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 11:42:38.224288: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[32m[I 2023-03-16 11:42:40,369]\u001b[0m Trial 0 finished with value: 0.909000039100647 and parameters: {'filters': 64, 'kernel_size': 3, 'strides': 2, 'activation': 'relu', 'learning_rate': 0.06992120542218803}. Best is trial 0 with value: 0.909000039100647.\u001b[0m\n",
      "2023-03-16 11:42:40.730866: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 11:42:41.121043: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[32m[I 2023-03-16 11:42:43,106]\u001b[0m Trial 1 finished with value: 0.8350000381469727 and parameters: {'filters': 64, 'kernel_size': 5, 'strides': 2, 'activation': 'linear', 'learning_rate': 0.046860663965596475}. Best is trial 0 with value: 0.909000039100647.\u001b[0m\n",
      "2023-03-16 11:42:43.433861: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 11:42:43.909881: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[32m[I 2023-03-16 11:42:45,909]\u001b[0m Trial 2 finished with value: 0.8400000333786011 and parameters: {'filters': 32, 'kernel_size': 3, 'strides': 2, 'activation': 'linear', 'learning_rate': 0.009106625180806096}. Best is trial 0 with value: 0.909000039100647.\u001b[0m\n",
      "2023-03-16 11:42:46.251901: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 11:42:46.806431: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[32m[I 2023-03-16 11:42:49,679]\u001b[0m Trial 3 finished with value: 0.9260000586509705 and parameters: {'filters': 64, 'kernel_size': 3, 'strides': 1, 'activation': 'relu', 'learning_rate': 0.0015054798883501238}. Best is trial 3 with value: 0.9260000586509705.\u001b[0m\n",
      "2023-03-16 11:42:50.031896: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 11:42:50.424334: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[32m[I 2023-03-16 11:42:52,619]\u001b[0m Trial 4 finished with value: 0.9440000653266907 and parameters: {'filters': 32, 'kernel_size': 3, 'strides': 1, 'activation': 'relu', 'learning_rate': 0.021408935173187347}. Best is trial 4 with value: 0.9440000653266907.\u001b[0m\n",
      "2023-03-16 11:42:52.942876: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 11:42:53.402726: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[32m[I 2023-03-16 11:42:56,252]\u001b[0m Trial 5 finished with value: 0.8650000691413879 and parameters: {'filters': 64, 'kernel_size': 3, 'strides': 1, 'activation': 'relu', 'learning_rate': 7.442994350097158e-05}. Best is trial 4 with value: 0.9440000653266907.\u001b[0m\n",
      "2023-03-16 11:42:56.589517: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 11:42:56.993407: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[32m[I 2023-03-16 11:42:59,009]\u001b[0m Trial 6 finished with value: 0.9110000729560852 and parameters: {'filters': 32, 'kernel_size': 5, 'strides': 2, 'activation': 'relu', 'learning_rate': 0.06924529320924303}. Best is trial 4 with value: 0.9440000653266907.\u001b[0m\n",
      "2023-03-16 11:42:59.354943: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 11:42:59.739747: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[32m[I 2023-03-16 11:43:01,782]\u001b[0m Trial 7 finished with value: 0.8380000591278076 and parameters: {'filters': 64, 'kernel_size': 3, 'strides': 2, 'activation': 'linear', 'learning_rate': 0.003541455702331529}. Best is trial 4 with value: 0.9440000653266907.\u001b[0m\n",
      "2023-03-16 11:43:02.133751: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 11:43:02.539749: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[32m[I 2023-03-16 11:43:04,636]\u001b[0m Trial 8 finished with value: 0.9200000166893005 and parameters: {'filters': 64, 'kernel_size': 5, 'strides': 2, 'activation': 'relu', 'learning_rate': 0.0010339851818062216}. Best is trial 4 with value: 0.9440000653266907.\u001b[0m\n",
      "2023-03-16 11:43:04.963202: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 11:43:05.427756: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[32m[I 2023-03-16 11:43:08,151]\u001b[0m Trial 9 finished with value: 0.8320000171661377 and parameters: {'filters': 64, 'kernel_size': 3, 'strides': 1, 'activation': 'linear', 'learning_rate': 0.08412369983520356}. Best is trial 4 with value: 0.9440000653266907.\u001b[0m\n",
      "2023-03-16 11:43:08.491756: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 11:43:08.919748: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[32m[I 2023-03-16 11:43:11,204]\u001b[0m Trial 10 finished with value: 0.8720000386238098 and parameters: {'filters': 32, 'kernel_size': 5, 'strides': 1, 'activation': 'relu', 'learning_rate': 0.00010194315338118295}. Best is trial 4 with value: 0.9440000653266907.\u001b[0m\n",
      "2023-03-16 11:43:11.567159: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 11:43:12.016651: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[32m[I 2023-03-16 11:43:14,437]\u001b[0m Trial 11 finished with value: 0.8950000405311584 and parameters: {'filters': 32, 'kernel_size': 3, 'strides': 1, 'activation': 'relu', 'learning_rate': 0.0003663247617090475}. Best is trial 4 with value: 0.9440000653266907.\u001b[0m\n",
      "2023-03-16 11:43:14.773530: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 11:43:15.217193: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "\u001b[33m[W 2023-03-16 11:43:16,011]\u001b[0m Trial 12 failed with parameters: {'filters': 32, 'kernel_size': 3, 'strides': 1, 'activation': 'relu', 'learning_rate': 1.2486375506410746e-05} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/5l/9brv6cdn1b97f82knqyjcb4m0000gn/T/ipykernel_46365/179757321.py\", line 68, in objective\n",
      "    model.fit(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/engine/training.py\", line 1445, in fit\n",
      "    val_logs = self.evaluate(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/engine/training.py\", line 1753, in evaluate\n",
      "    for step in data_handler.steps():\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1248, in steps\n",
      "    original_spe = self._steps_per_execution.numpy().item()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 637, in numpy\n",
      "    return self.read_value().numpy()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1159, in numpy\n",
      "    maybe_arr = self._numpy()  # pylint: disable=protected-access\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1125, in _numpy\n",
      "    return self._numpy_internal()\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-03-16 11:43:16,015]\u001b[0m Trial 12 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/leoglonz/Desktop/stock_analysis/test.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 83>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mRecent Keras release (2.4.0) simply redirects all APIs \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39min the standalone keras package to point to tf.keras. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mREF:https://github.com/keras-team/keras/releases/tag/2.4.0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, timeout\u001b[39m=\u001b[39;49m\u001b[39m600\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNumber of finished trials: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mlen\u001b[39m(study\u001b[39m.\u001b[39mtrials)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest trial:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/optuna/study/study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    322\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    332\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \n\u001b[1;32m    334\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     _optimize(\n\u001b[1;32m    426\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    427\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    428\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    429\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    430\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    431\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    432\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    433\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    434\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    435\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/Users/leoglonz/Desktop/stock_analysis/test.ipynb Cell 1\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m learning_rate \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39msuggest_float(\u001b[39m\"\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1e-5\u001b[39m, \u001b[39m1e-1\u001b[39m, log\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     optimizer\u001b[39m=\u001b[39mRMSprop(learning_rate\u001b[39m=\u001b[39mlearning_rate),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     x_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     y_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(x_valid, y_valid),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mBATCHSIZE,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mEPOCHS,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39m# Evaluate the model accuracy on the validation set.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test.ipynb#W0sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m score \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(x_valid, y_valid, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/engine/training.py:1445\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1432\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[1;32m   1433\u001b[0m       x\u001b[39m=\u001b[39mval_x,\n\u001b[1;32m   1434\u001b[0m       y\u001b[39m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1443\u001b[0m       model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m   1444\u001b[0m       steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution)\n\u001b[0;32m-> 1445\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m   1446\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[1;32m   1447\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[1;32m   1448\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[1;32m   1449\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[1;32m   1450\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   1451\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1452\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1453\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1454\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1455\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1456\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1457\u001b[0m val_logs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m   1458\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/engine/training.py:1753\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_metrics()\n\u001b[1;32m   1752\u001b[0m \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m-> 1753\u001b[0m   \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[1;32m   1754\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1755\u001b[0m       callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/engine/data_adapter.py:1248\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m   \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1248\u001b[0m original_spe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution\u001b[39m.\u001b[39;49mnumpy()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m   1249\u001b[0m can_run_full_execution \u001b[39m=\u001b[39m (\n\u001b[1;32m   1250\u001b[0m     original_spe \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1252\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m\n\u001b[1;32m   1253\u001b[0m     original_spe)\n\u001b[1;32m   1255\u001b[0m \u001b[39mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnumpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    636\u001b[0m   \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 637\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_value()\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    638\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    639\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1159\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \n\u001b[1;32m   1138\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1159\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1160\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1125\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1124\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1125\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1126\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Optuna example that optimizes a neural network classifier configuration for the\n",
    "MNIST dataset using Keras.\n",
    "In this example, we optimize the validation accuracy of MNIST classification using\n",
    "Keras. We optimize the filter and kernel size, kernel stride and layer activation.\n",
    "\"\"\"\n",
    "import urllib\n",
    "import warnings\n",
    "\n",
    "import optuna\n",
    "\n",
    "from keras.backend import clear_session\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "# TODO(crcrpar): Remove the below three lines once everything is ok.\n",
    "# Register a global custom opener to avoid HTTP Error 403: Forbidden when downloading MNIST.\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [(\"User-agent\", \"Mozilla/5.0\")]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "\n",
    "N_TRAIN_EXAMPLES = 3000\n",
    "N_VALID_EXAMPLES = 1000\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "EPOCHS = 10\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Clear clutter from previous Keras session graphs.\n",
    "    clear_session()\n",
    "\n",
    "    (x_train, y_train), (x_valid, y_valid) = mnist.load_data()\n",
    "    img_x, img_y = x_train.shape[1], x_train.shape[2]\n",
    "    x_train = x_train.reshape(-1, img_x, img_y, 1)[:N_TRAIN_EXAMPLES].astype(\"float32\") / 255\n",
    "    x_valid = x_valid.reshape(-1, img_x, img_y, 1)[:N_VALID_EXAMPLES].astype(\"float32\") / 255\n",
    "    y_train = y_train[:N_TRAIN_EXAMPLES]\n",
    "    y_valid = y_valid[:N_VALID_EXAMPLES]\n",
    "    input_shape = (img_x, img_y, 1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            filters=trial.suggest_categorical(\"filters\", [32, 64]),\n",
    "            kernel_size=trial.suggest_categorical(\"kernel_size\", [3, 5]),\n",
    "            strides=trial.suggest_categorical(\"strides\", [1, 2]),\n",
    "            activation=trial.suggest_categorical(\"activation\", [\"relu\", \"linear\"]),\n",
    "            input_shape=input_shape,\n",
    "        )\n",
    "    )\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(CLASSES, activation=\"softmax\"))\n",
    "\n",
    "    # We compile our model with a sampled learning rate.\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=RMSprop(learning_rate=learning_rate),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        validation_data=(x_valid, y_valid),\n",
    "        shuffle=True,\n",
    "        batch_size=BATCHSIZE,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # Evaluate the model accuracy on the validation set.\n",
    "    score = model.evaluate(x_valid, y_valid, verbose=0)\n",
    "    return score[1]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    warnings.warn(\n",
    "        \"Recent Keras release (2.4.0) simply redirects all APIs \"\n",
    "        \"in the standalone keras package to point to tf.keras. \"\n",
    "        \"There is now only one Keras: tf.keras. \"\n",
    "        \"There may be some breaking changes for some workflows by upgrading to keras 2.4.0. \"\n",
    "        \"Test before upgrading. \"\n",
    "        \"REF:https://github.com/keras-team/keras/releases/tag/2.4.0\"\n",
    "    )\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
