{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import RandomSampler\n",
    "\n",
    "\n",
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yfin\n",
    "import datetime as dt\n",
    "\n",
    "# Yahoo API may have broken previous versions of pd_datareader, so this is a workaround.\n",
    "yfin.pdr_override()\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "2065 unique points loaded with attributes: \n",
      " Index(['Open', 'High', 'Low', 'Close', 'AdjClose', 'Volume'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Yahoo Finance stock scraping.\n",
    "# **Careful with how many times you run this to avoid IP ban**\n",
    "TICKER = 'GOOG'\n",
    "START = dt.datetime(2015, 1, 1)\n",
    "END = dt.datetime.today()\n",
    "\n",
    "stock = pdr.get_data_yahoo(TICKER, START, END).rename(columns= {'Adj Close': 'AdjClose'})\n",
    "\n",
    "print(stock.shape[0], \"unique points loaded with attributes: \\n\", stock.\n",
    "      keys())\n",
    "\n",
    "def series_to_supervised(data, n_in=5, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "    data: Sequence of observations as a list or NumPy array.\n",
    "    n_in: Number of lag observations as input (X).\n",
    "    n_out: Number of observations as output (y).\n",
    "    dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "    Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "    if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "    else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    \n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "        \n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Specify number of days to use for beta calculation (255 = 1yr).\n",
    "window = 252 \n",
    "\n",
    "# Specify a market highly correlated with 'stock'.\n",
    "market_ticker = 'SPY'\n",
    "\n",
    "def beta(df, market=None):\n",
    "    # If the market values are not passed,\n",
    "    # I'll assume they are located in a column\n",
    "    # named 'Market'.  If not, this will fail.\n",
    "    if market is None:\n",
    "        market = df['MarketClose']\n",
    "        df = df.drop('MarketClose', axis=1)\n",
    "    X = market.values.reshape(-1, 1)\n",
    "    X = np.concatenate([np.ones_like(X), X], axis=1)\n",
    "    b = np.linalg.pinv(X.T.dot(X)).dot(X.T).dot(df.values)\n",
    "    return float(b[1])\n",
    "\n",
    "def roll(df, w=252):\n",
    "    # Takes 'w'-sized slices from dataframe, incrementing 1 entry at a time.\n",
    "    for i in range(df.shape[0] - w + 1):\n",
    "        yield pd.DataFrame(df.values[i:i+w, :], df.index[i:i+w],\n",
    "                           df.columns)\n",
    "\n",
    "\n",
    "#### Combining stock + market data and computing.\n",
    "market = pdr.get_data_yahoo(market_ticker,\n",
    "                            START,\n",
    "                            END).rename(columns={'Adj Close': 'MarketClose'})\n",
    "\n",
    "betas = np.array([])\n",
    "dat = pd.concat([stock.AdjClose, market.MarketClose], axis=1)\n",
    "len(dat)\n",
    "\n",
    "for  i, sdf in enumerate(roll(dat.pct_change().dropna(), window)):\n",
    "    betas = np.append(betas, beta(sdf))\n",
    "\n",
    "datFull = dat.drop(index=dat.index[:window], axis=0, inplace=False)\n",
    "datFull['Beta'] = betas.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAG = 60 # Number of days to use for predicting the following day(s).\n",
    "DAYS = 1 # Number of days to predict with each lag period.\n",
    "TRAIN_RATIO = 0.70\n",
    "\n",
    "\n",
    "# Selecting 'AdjClose' prices as input and target feature for time series.\n",
    "data = dat.filter(['AdjClose']).values\n",
    "\n",
    "# Scaling data. Ensures quicker convergence to solution.\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Splitting input features and target object, X and y.\n",
    "supervised_data = series_to_supervised(scaled_data, n_in=LAG, n_out=DAYS)\n",
    "y = supervised_data['var1(t)'] # Isolating target object.\n",
    "X = supervised_data.loc[:, supervised_data.columns != 'var1(t)'] \n",
    "\n",
    "# Selecting converted data for train-test split.\n",
    "len_training = int(np.ceil(len(scaled_data) * TRAIN_RATIO))\n",
    "\n",
    "X_train = X.iloc[0:len_training].to_numpy()\n",
    "y_train = y.iloc[0:len_training].to_numpy()\n",
    "# X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "# We subtract lag since we need the lag days to actually make test predictions.\n",
    "X_test = X.iloc[len_training-60:].to_numpy()\n",
    "y_test = data[len_training:]\n",
    "\n",
    "# Reshaping to obtain 3D reps (currently 2d) to pass into LSTM.\n",
    "# LSTM expects d1 # of samples, d2 # of timesteps, and d3 # of features.\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "if len(X_test) != len(y_test):\n",
    "    raise Warning('X_test, y_test length mismatch.')\n",
    "\n",
    "# generator = TimeseriesGenerator(scaled_data, scaled_data, length=60, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "data1 = dat = datImport(TICKER, start = START, end=END, verbose=False)\n",
    "X_train1, y_train1, X_test1, y_test1, scaler1 = data_split(data1, LAG, DAYS, TRAIN_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1446, 1446)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datImport(ticker, start=dt.datetime(2023,1,1), end=dt.datetime.today(), verbose=False):\n",
    "    # importing daily equity or market data.\n",
    "    data = pdr.get_data_yahoo(ticker, start, end).rename(columns= {'Adj Close': 'AdjClose'})\n",
    "\n",
    "    if verbose:\n",
    "        print(data.shape[0], \"days loaded with attributes: \\n\", data.keys())\n",
    "\n",
    "        fig, ax = plt.subplots(1,1, dpi=300, figsize=(16,8),\n",
    "            constrained_layout=False)\n",
    "\n",
    "        ax.plot(data.index, data.AdjClose)\n",
    "\n",
    "        ax.set_title(\"Adjusted Closing Prices for %s (USD), %s-%s\" \n",
    "                    %(ticker, start.year, end.year))\n",
    "        ax.set_xlabel('Date', fontsize=18)\n",
    "        ax.set_ylabel('Adjusted Closing Price (USD)', fontsize=18)\n",
    "\n",
    "        # Set major and minor date tick locators\n",
    "        maj_loc = mdates.MonthLocator(bymonth=np.arange(1,12,6))\n",
    "        ax.xaxis.set_major_locator(maj_loc)\n",
    "        min_loc = mdates.MonthLocator()\n",
    "        ax.xaxis.set_minor_locator(min_loc)\n",
    "\n",
    "        # Set major date tick formatter\n",
    "        zfmts = ['', '%b\\n%Y', '%b', '%b-%d', '%H:%M', '%H:%M']\n",
    "        maj_fmt = mdates.ConciseDateFormatter(maj_loc, zero_formats=zfmts, \n",
    "                                            show_offset=False)\n",
    "        ax.xaxis.set_major_formatter(maj_fmt)\n",
    "\n",
    "        ax.figure.autofmt_xdate(rotation=0, ha='center')\n",
    "        ax.set_xlim(data.index.min(), data.index.max());\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "START = dt.datetime(2015, 1, 1)\n",
    "END = dt.datetime.today()\n",
    "TICKER = 'GOOG'\n",
    "\n",
    "dat = datImport(TICKER, start = START, end=END, verbose=False)\n",
    "\n",
    "# data = pdr.get_data_yahoo(TICKER, START, END) #.rename(columns= {'Adj Close': 'AdjClose'})\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAG = 60 # Number of days to use for predicting the following day(s).\n",
    "DAYS = 1 # Number of days to predict with each lag period.\n",
    "TRAIN_RATIO = 0.70\n",
    "\n",
    "def data_split(data, lag=60, days=1, train_ratio=0.70):\n",
    "    \"\"\"\n",
    "    Prepping stock data for neural net; scaling down \n",
    "    values and making train-test split.\n",
    "    data: DataFrame, all stock data.\n",
    "    lag: int, number of days used for prediction.\n",
    "    days: int, number of days to predict.\n",
    "    train_ratio: float, percentage of data for training.\n",
    "    Returns\n",
    "        X_train: array, independent training features.\n",
    "        y_train: array, objective training feature.\n",
    "        X_test: array, independent test features.\n",
    "        y_test: array, objective test feature.\n",
    "    \"\"\"\n",
    "    # Selecting 'AdjClose' prices as input and target feature for time series.\n",
    "    data_adj = data.filter(['AdjClose']).values\n",
    "\n",
    "    # Scaling data. Ensures quicker convergence to solution.\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    scaled_data = scaler.fit_transform(data_adj)\n",
    "\n",
    "    # Splitting input features and target object, X and y.\n",
    "    supervised_data = series_to_supervised(scaled_data, n_in=lag, n_out=days)\n",
    "    y = supervised_data['var1(t)'] # Isolating target object.\n",
    "    X = supervised_data.loc[:, supervised_data.columns != 'var1(t)'] \n",
    "\n",
    "    # Selecting converted data for train-test split.\n",
    "    len_training = int(np.ceil(len(scaled_data) * train_ratio))\n",
    "\n",
    "    X_train = X.iloc[0:len_training].to_numpy()\n",
    "    y_train = y.iloc[0:len_training].to_numpy()\n",
    "    # X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "    # We subtract lag since we need the lag days to actually make test predictions.\n",
    "    X_test = X.iloc[len_training-60:].to_numpy()\n",
    "    y_test = data_adj[len_training:]\n",
    "\n",
    "    # Reshaping to obtain 3D reps (currently 2d) to pass into LSTM.\n",
    "    # LSTM expects d1 # of samples, d2 # of timesteps, and d3 # of features.\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    if len(X_test) != len(y_test):\n",
    "        raise Warning('X_test, y_test length mismatch.')\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, y_train1, X_test1, y_test1, scaler1 = data_split(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from base import *\n",
    "\n",
    "LAG = 60 # Number of days to use for predicting the following day(s).\n",
    "DAYS = 1 # Number of days to predict with each lag period.\n",
    "TRAIN_RATIO = 0.70\n",
    "\n",
    "TICKER = 'GOOG'\n",
    "START = dt.datetime(2015, 1, 1)\n",
    "END = dt.datetime.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "data1 = dat = datImport(TICKER, start = START, end=END, verbose=False)\n",
    "X_train1, y_train1, X_test1, y_test1, scaler1 = data_split(data1, LAG, DAYS, TRAIN_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.01275146],\n",
       "        [0.0084272 ],\n",
       "        [0.00371951],\n",
       "        ...,\n",
       "        [0.02475193],\n",
       "        [0.02205221],\n",
       "        [0.02351077]],\n",
       "\n",
       "       [[0.0084272 ],\n",
       "        [0.00371951],\n",
       "        [0.00337958],\n",
       "        ...,\n",
       "        [0.02205221],\n",
       "        [0.02351077],\n",
       "        [0.02191782]],\n",
       "\n",
       "       [[0.00371951],\n",
       "        [0.00337958],\n",
       "        [0.00400411],\n",
       "        ...,\n",
       "        [0.02351077],\n",
       "        [0.02191782],\n",
       "        [0.01976754]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.37802882],\n",
       "        [0.38578154],\n",
       "        [0.38768802],\n",
       "        ...,\n",
       "        [0.50408618],\n",
       "        [0.49810115],\n",
       "        [0.4914067 ]],\n",
       "\n",
       "       [[0.38578154],\n",
       "        [0.38768802],\n",
       "        [0.38779507],\n",
       "        ...,\n",
       "        [0.49810115],\n",
       "        [0.4914067 ],\n",
       "        [0.49472024]],\n",
       "\n",
       "       [[0.38768802],\n",
       "        [0.38779507],\n",
       "        [0.39591641],\n",
       "        ...,\n",
       "        [0.4914067 ],\n",
       "        [0.49472024],\n",
       "        [0.48843009]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/leoglonz/Desktop/stock_analysis/test_mine.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test_mine.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m v\u001b[39m=\u001b[39m [X_train1, y_train1, X_test1, y_test1, scaler1]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test_mine.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# v[:], np.array(X_train1)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test_mine.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m x, y \u001b[39m=\u001b[39m v[\u001b[39m0\u001b[39m::\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "v= [X_train1, y_train1, X_test1, y_test1, scaler1]\n",
    "\n",
    "# v[:], np.array(X_train1)\n",
    "x, y = v[0::1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set a frame with no defined index and a value that cannot be converted to a Series",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pandas/core/frame.py:3892\u001b[0m, in \u001b[0;36mDataFrame._ensure_valid_index\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3892\u001b[0m     value \u001b[39m=\u001b[39m Series(value)\n\u001b[1;32m   3893\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pandas/core/series.py:451\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 451\u001b[0m     data \u001b[39m=\u001b[39m sanitize_array(data, index, dtype, copy)\n\u001b[1;32m    453\u001b[0m     manager \u001b[39m=\u001b[39m get_option(\u001b[39m\"\u001b[39m\u001b[39mmode.data_manager\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pandas/core/construction.py:601\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[1;32m    599\u001b[0m             subarr \u001b[39m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[0;32m--> 601\u001b[0m subarr \u001b[39m=\u001b[39m _sanitize_ndim(subarr, data, dtype, index, allow_2d\u001b[39m=\u001b[39;49mallow_2d)\n\u001b[1;32m    603\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(subarr, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m    604\u001b[0m     \u001b[39m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pandas/core/construction.py:652\u001b[0m, in \u001b[0;36m_sanitize_ndim\u001b[0;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m--> 652\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mData must be 1-dimensional\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    653\u001b[0m \u001b[39mif\u001b[39;00m is_object_dtype(dtype) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[1;32m    654\u001b[0m     \u001b[39m# i.e. PandasDtype(\"O\")\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Data must be 1-dimensional",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/leoglonz/Desktop/stock_analysis/test_mine.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test_mine.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test_mine.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/leoglonz/Desktop/stock_analysis/test_mine.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df[\u001b[39m'\u001b[39;49m\u001b[39mdat\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(X_train1)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pandas/core/frame.py:3655\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3653\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3654\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3655\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pandas/core/frame.py:3832\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3822\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3823\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   3825\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3830\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   3831\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3832\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   3834\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   3835\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   3836\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   3837\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   3838\u001b[0m     ):\n\u001b[1;32m   3839\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   3840\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pandas/core/frame.py:4528\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4515\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sanitize_column\u001b[39m(\u001b[39mself\u001b[39m, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ArrayLike:\n\u001b[1;32m   4516\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4517\u001b[0m \u001b[39m    Ensures new columns (which go into the BlockManager as new blocks) are\u001b[39;00m\n\u001b[1;32m   4518\u001b[0m \u001b[39m    always copied and converted into an array.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4526\u001b[0m \u001b[39m    numpy.ndarray or ExtensionArray\u001b[39;00m\n\u001b[1;32m   4527\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4528\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ensure_valid_index(value)\n\u001b[1;32m   4530\u001b[0m     \u001b[39m# We should never get here with DataFrame value\u001b[39;00m\n\u001b[1;32m   4531\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, Series):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pandas/core/frame.py:3894\u001b[0m, in \u001b[0;36mDataFrame._ensure_valid_index\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   3892\u001b[0m         value \u001b[39m=\u001b[39m Series(value)\n\u001b[1;32m   3893\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3894\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   3895\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCannot set a frame with no defined index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3896\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mand a value that cannot be converted to a Series\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3897\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3899\u001b[0m \u001b[39m# GH31368 preserve name of index\u001b[39;00m\n\u001b[1;32m   3900\u001b[0m index_copy \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mcopy()\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot set a frame with no defined index and a value that cannot be converted to a Series"
     ]
    }
   ],
   "source": [
    "pd.DataFrame({'Column1': Xte, 'Column2': data[:, 1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.01275146],\n",
       "        [0.0084272 ],\n",
       "        [0.00371951],\n",
       "        ...,\n",
       "        [0.02475193],\n",
       "        [0.02205221],\n",
       "        [0.02351077]],\n",
       "\n",
       "       [[0.0084272 ],\n",
       "        [0.00371951],\n",
       "        [0.00337958],\n",
       "        ...,\n",
       "        [0.02205221],\n",
       "        [0.02351077],\n",
       "        [0.02191782]],\n",
       "\n",
       "       [[0.00371951],\n",
       "        [0.00337958],\n",
       "        [0.00400411],\n",
       "        ...,\n",
       "        [0.02351077],\n",
       "        [0.02191782],\n",
       "        [0.01976754]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.37802882],\n",
       "        [0.38578154],\n",
       "        [0.38768802],\n",
       "        ...,\n",
       "        [0.50408618],\n",
       "        [0.49810115],\n",
       "        [0.4914067 ]],\n",
       "\n",
       "       [[0.38578154],\n",
       "        [0.38768802],\n",
       "        [0.38779507],\n",
       "        ...,\n",
       "        [0.49810115],\n",
       "        [0.4914067 ],\n",
       "        [0.49472024]],\n",
       "\n",
       "       [[0.38768802],\n",
       "        [0.38779507],\n",
       "        [0.39591641],\n",
       "        ...,\n",
       "        [0.4914067 ],\n",
       "        [0.49472024],\n",
       "        [0.48843009]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
