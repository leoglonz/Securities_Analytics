{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import RandomSampler\n",
    "\n",
    "\n",
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yfin\n",
    "import datetime as dt\n",
    "\n",
    "# Yahoo API may have broken previous versions of pd_datareader, so this is a workaround.\n",
    "yfin.pdr_override()\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "2818 unique points loaded with attributes: \n",
      " Index(['Open', 'High', 'Low', 'Close', 'AdjClose', 'Volume'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Yahoo Finance stock scraping.\n",
    "# **Careful with how many times you run this to avoid IP ban**\n",
    "TICKER = 'AMZN'\n",
    "START = dt.datetime(2012, 1, 1)\n",
    "END = dt.datetime.today()\n",
    "\n",
    "stock = pdr.get_data_yahoo(TICKER, START, END).rename(columns= {'Adj Close': 'AdjClose'})\n",
    "\n",
    "print(stock.shape[0], \"unique points loaded with attributes: \\n\", stock.\n",
    "      keys())\n",
    "\n",
    "def series_to_supervised(data, n_in=5, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "    data: Sequence of observations as a list or NumPy array.\n",
    "    n_in: Number of lag observations as input (X).\n",
    "    n_out: Number of observations as output (y).\n",
    "    dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "    Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "    if i == 0:\n",
    "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "    else:\n",
    "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    \n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "        \n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Specify number of days to use for beta calculation (255 = 1yr).\n",
    "window = 252 \n",
    "\n",
    "# Specify a market highly correlated with 'stock'.\n",
    "market_ticker = 'SPY'\n",
    "\n",
    "def beta(df, market=None):\n",
    "    # If the market values are not passed,\n",
    "    # I'll assume they are located in a column\n",
    "    # named 'Market'.  If not, this will fail.\n",
    "    if market is None:\n",
    "        market = df['MarketClose']\n",
    "        df = df.drop('MarketClose', axis=1)\n",
    "    X = market.values.reshape(-1, 1)\n",
    "    X = np.concatenate([np.ones_like(X), X], axis=1)\n",
    "    b = np.linalg.pinv(X.T.dot(X)).dot(X.T).dot(df.values)\n",
    "    return float(b[1])\n",
    "\n",
    "def roll(df, w=252):\n",
    "    # Takes 'w'-sized slices from dataframe, incrementing 1 entry at a time.\n",
    "    for i in range(df.shape[0] - w + 1):\n",
    "        yield pd.DataFrame(df.values[i:i+w, :], df.index[i:i+w],\n",
    "                           df.columns)\n",
    "\n",
    "\n",
    "#### Combining stock + market data and computing.\n",
    "market = pdr.get_data_yahoo(market_ticker,\n",
    "                            START,\n",
    "                            END).rename(columns={'Adj Close': 'MarketClose'})\n",
    "\n",
    "betas = np.array([])\n",
    "dat = pd.concat([stock.AdjClose, market.MarketClose], axis=1)\n",
    "\n",
    "for  i, sdf in enumerate(roll(dat.pct_change().dropna(), window)):\n",
    "    betas = np.append(betas, beta(sdf))\n",
    "\n",
    "datFull = dat.drop(index=dat.index[:window], axis=0, inplace=False)\n",
    "datFull['Beta'] = betas.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAG = 60 # Number of days to use for predicting the following day(s).\n",
    "DAYS = 1 # Number of days to predict with each lag period.\n",
    "TRAIN_RATIO = 0.70\n",
    "\n",
    "\n",
    "# Selecting 'AdjClose' prices as input and target feature for time series.\n",
    "data = datFull.filter(['AdjClose']).values\n",
    "\n",
    "# Scaling data. Ensures quicker convergence to solution.\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Splitting input features and target object, X and y.\n",
    "supervised_data = series_to_supervised(scaled_data, n_in=LAG, n_out=DAYS)\n",
    "y = supervised_data['var1(t)'] # Isolating target object.\n",
    "X = supervised_data.loc[:, supervised_data.columns != 'var1(t)'] \n",
    "\n",
    "# Selecting converted data for train-test split.\n",
    "len_training = int(np.ceil(len(scaled_data) * TRAIN_RATIO))\n",
    "\n",
    "X_train = X.iloc[0:len_training].to_numpy()\n",
    "y_train = y.iloc[0:len_training].to_numpy()\n",
    "# X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "# We subtract lag since we need the lag days to actually make test predictions.\n",
    "X_test = X.iloc[len_training-60:].to_numpy()\n",
    "y_test = data[len_training:]\n",
    "\n",
    "# Reshaping to obtain 3D reps (currently 2d) to pass into LSTM.\n",
    "# LSTM expects d1 # of samples, d2 # of timesteps, and d3 # of features.\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "if len(X_test) != len(y_test):\n",
    "    raise Warning('X_test, y_test length mismatch.')\n",
    "\n",
    "# generator = TimeseriesGenerator(scaled_data, scaled_data, length=60, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5l/9brv6cdn1b97f82knqyjcb4m0000gn/T/ipykernel_46436/4143984575.py:109: UserWarning: Layer LSTM will only use cuDNN high-efficiency kernals\n",
      "when training with layer params 'activation==tanh'\n",
      "'recurrent_activation==sigmoid', 'unroll=False',\n",
      "'use_bias=True', and 'recurrent_dropout=0.0'.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-03-16 12:04:06,042]\u001b[0m A new study created in memory with name: test\u001b[0m\n",
      "2023-03-16 12:04:07.021553: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 12:04:07.333624: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 12:04:07.515229: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 12:04:07.786040: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 12:04:08.079546: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - ETA: 0s - loss: 0.0721 - accuracy: 5.5648e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 12:04:09.910258: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 12:04:10.013151: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 12:04:10.144007: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 4s 171ms/step - loss: 0.0721 - accuracy: 5.5648e-04 - val_loss: 20837.6113 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 12:04:10.913168: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 12:04:11.004845: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/25 [>.............................] - ETA: 13s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 12:04:11.131522: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-16 12:04:11,933]\u001b[0m Trial 0 finished with value: 126.74019886334324 and parameters: {'unit': 94, 'droupout': 0.5911348488264657, 'learning_rate': 0.006537840599765375}. Best is trial 0 with value: 126.74019886334324.\u001b[0m\n",
      "2023-03-16 12:04:12.965395: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 12:04:13.278528: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 12:04:13.444920: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 12:04:13.748924: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 12:04:14.118341: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 5.5648e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 12:04:16.544239: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 12:04:16.660107: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 12:04:16.793230: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 5s 212ms/step - loss: 0.0606 - accuracy: 5.5648e-04 - val_loss: 20822.9980 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 12:04:17.528861: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 12:04:17.624380: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/25 [>.............................] - ETA: 13s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 12:04:17.755962: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-16 12:04:18,540]\u001b[0m Trial 1 finished with value: 118.01529811417637 and parameters: {'unit': 68, 'droupout': 0.5121910829577211, 'learning_rate': 7.297797251116168e-05}. Best is trial 0 with value: 126.74019886334324.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 2\n",
      "Best trial:\n",
      "  Value: 126.74019886334324\n",
      "  Params: \n",
      "    unit: 94\n",
      "    droupout: 0.5911348488264657\n",
      "    learning_rate: 0.006537840599765375\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Optuna implementation that optimizes an LSTM neural network lag series \n",
    "stock data using Keras.\n",
    "\n",
    "We optimize LSTM units, LSTM layer dropout, and learning rate.\n",
    "\n",
    "IN PROGRESS\n",
    "Last Revised: 15 Mar 2023\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "BATCHSIZE = 128 #128\n",
    "CLASSES = 10\n",
    "EPOCHS = 1 #10\n",
    "\n",
    "\n",
    "def create_model(trial):\n",
    "    model = Sequential()\n",
    "\n",
    "    units=trial.suggest_int('unit', 64, 128, step=2)\n",
    "    model.add(\n",
    "        LSTM(\n",
    "            units=units,\n",
    "            activation='tanh',\n",
    "            recurrent_activation='sigmoid',\n",
    "            unroll=False,\n",
    "            use_bias=True,\n",
    "            dropout=trial.suggest_float('droupout', 0, 1),\n",
    "            # recurrent_dropout=trial.suggest_float('recurrent_droupout', 0, 1),\n",
    "            return_sequences=True,\n",
    "            input_shape=(X_train.shape[1], 1)\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        LSTM(\n",
    "            units=int(units/2),\n",
    "            activation='tanh',\n",
    "            recurrent_activation='sigmoid',\n",
    "            unroll=False,\n",
    "            use_bias=True,\n",
    "            dropout=trial.suggest_float('droupout', 0, 1),\n",
    "            # recurrent_dropout=trial.suggest_float('recurrent_droupout', 0, 1),\n",
    "            return_sequences=False,\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        Dense(\n",
    "            CLASSES,\n",
    "            activation='relu',\n",
    "            use_bias=True\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        Dense(\n",
    "            1,\n",
    "            activation='relu',\n",
    "            use_bias=True\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # We compile our model with a sampled learning rate.\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    model.compile(\n",
    "        loss=\"mean_squared_error\",\n",
    "        optimizer=Adam(\n",
    "            learning_rate=0, # learning_rate,\n",
    "            beta_1=0.9,\n",
    "            beta_2=0.999,\n",
    "            epsilon=1e-07\n",
    "        ),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        shuffle=True,\n",
    "        batch_size=BATCHSIZE,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # Evaluate the model accuracy on the validation set.\n",
    "    score = model.evaluate(X_test, y_test, verbose=True)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "    # RMSE.\n",
    "    rmse = np.sqrt(np.mean(predictions - y_test)**2)\n",
    "\n",
    "    return rmse #score[1]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study_name = 'test'\n",
    "    n_trials = 2\n",
    "    warnings.warn(\n",
    "        \"Layer LSTM will only use cuDNN high-efficiency kernals\\n\"\n",
    "        \"when training with layer params 'activation==tanh'\\n\"\n",
    "        \"'recurrent_activation==sigmoid', 'unroll=False',\\n\"\n",
    "        \"'use_bias=True', and 'recurrent_dropout=0.0'.\"\n",
    "    )\n",
    "    study = optuna.create_study(direction=\"maximize\", study_name=study_name)\n",
    "    # Use n_jobs=-1 for full parallelization.\n",
    "    study.optimize(objective, n_trials=n_trials, n_jobs=1, timeout=600)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 'direction='minimize' to minimize runtime, 'maximize' accuracy.\n",
    "study = optuna.create_study(sampler=RandomSampler(seed=40),\n",
    "                            direction=\"minimize\",\n",
    "                            study_name='StockOpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5l/9brv6cdn1b97f82knqyjcb4m0000gn/T/ipykernel_46436/3076746956.py:33: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  estimator = KerasClassifier(build_fn=baseline_model, epochs=200, verbose=0)\n",
      "2023-03-16 13:01:18.253206: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 13:01:31.381487: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 13:01:31.649176: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 13:01:43.658059: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 13:01:43.877487: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 17 calls to <function Model.make_test_function.<locals>.test_function at 0x336dc5ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 13:01:56.132536: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 13:01:56.363459: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x2de144ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 13:02:08.278950: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 13:02:08.535369: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 13:02:20.717657: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 13:02:20.956950: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 13:02:33.438043: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 13:02:33.694185: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 13:02:45.926007: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 13:02:46.149058: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 13:02:57.883780: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 13:02:58.096592: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 13:03:09.930811: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-16 13:03:10.152801: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9333334  1.         1.         1.         1.         1.\n",
      " 1.         0.86666673 1.         0.86666673]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 13:03:21.906189: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "X, encoded_Y = load_iris(return_X_y=True)\n",
    "mms = MinMaxScaler()\n",
    "X = mms.fit_transform(X)\n",
    "\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "def baseline_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4, input_dim=4, activation=\"relu\", kernel_initializer=\"normal\"))\n",
    "    model.add(Dense(8, activation=\"relu\", kernel_initializer=\"normal\"))\n",
    "    model.add(Dense(3, activation=\"softmax\", kernel_initializer=\"normal\"))\n",
    "\n",
    "    model.compile(loss= 'categorical_crossentropy' , optimizer='adam', metrics=[\n",
    "        'accuracy' ])\n",
    "\n",
    "    return model\n",
    "\n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
